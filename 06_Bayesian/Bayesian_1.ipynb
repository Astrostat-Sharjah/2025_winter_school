{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b33d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4381d2",
   "metadata": {},
   "source": [
    "<font size=6>**Introduction to Bayesian Statistics**</font>\n",
    "\n",
    "\n",
    "# 1. The problem: Counting photons...\n",
    "\n",
    "Typically, an X-ray imaging observation gives a collection of <span style=\"color:#d87c3a\">**events**</span>: coordinates and energies of <span style=\"color:#d87c3a\">**individual photons**</span> detected by the telescope. Essentially, we count photons, and this is why we usually refer to the photons as <span style=\"color:#d87c3a\">**counts**</span>, while the <span style=\"color:#d87c3a\">**count rate**</span> informs us about the number of photons per second. In general, the <span style=\"color:#d87c3a\">*count rate scales with the flux*</span> of the field (or source) in the energy band of the telescope during the observation.\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"images/NGC1482_opt.jpg\" alt=\"Drawing\" style=\"height:400px;\"/> </td>\n",
    "<td> <img src=\"images/NGC1482.png\" alt=\"Drawing\" style=\"height: 400px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Using <span style=\"color:#d87c3a\">**source detection algorithms**</span> we group photons together and generate a <span style=\"color:#d87c3a\">list of sources and the photons we got from each</span> - namely, the *source region*. \n",
    "- For a given source, the *integrated energy of the photons from its source region* gives us an estimate on the *energy collected from the telescope*. Of course, the response of the detector and absorption effects should be accounted for. \n",
    "- Having *many counts* allows us to *fit for the spectrum* of the source. \n",
    "- Modeling the detector properties, the intergalactic absorption and the spectra allows us to <span style=\"color:#d87c3a\">measure the *bolometric* flux</span> of the source - the flux as if we could observe the source with a perfect detector. \n",
    "- Provided we know the distance of the source we can <span style=\"color:#d87c3a\">convert from flux to luminosity</span>... an intrinsic property of the source (which is what we usually care for)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c682e",
   "metadata": {},
   "source": [
    "## 1.1. How many counts are we going to get?\n",
    "\n",
    "<font size=3><u>**In-class discussion: If each photon count during the exposure (e.g., 50 ks) corresponds to luminosity $10^{38}\\,\\rm erg\\,s^{-1}$, and our souce is $5\\times 10^{38}\\,\\rm erg\\,s^{-1}$, what is **on average** the number of counts we will measure?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Simply dividing we get the number of counts!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e858f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT_TO_LUMINOSITY = 1.0e38  # in erg/s\n",
    "source_luminosity = 5.0e38    # in erg/s\n",
    "expected_counts = source_luminosity / COUNT_TO_LUMINOSITY\n",
    "print(f\"Expected counts: {expected_counts:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5dfbf7",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: What is the distribution of the potential multiple count measurements?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "It's a counting problem, and we expect that it's measurement is independent (arrivals of photons, multiple experiments), so... it's Poisson!\n",
    "    \n",
    "$$ P(\\textrm{counts} | \\textrm{expected}) = P(k | \\lambda) = \\textrm{Pois}(k; \\lambda) = \\dfrac{\\lambda^k e^{-\\lambda}}{k!} $$\n",
    "<br>\n",
    "\n",
    "> **Reminder**: *Poisson distribution* is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time if these events occur with a known constant mean rate and independently of the time since the last event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b566fe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Select the appropriate distribution and plot it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = np.arange(0, int(expected_counts*3)+1, 1)\n",
    "pmf = st...()...(outcomes)\n",
    "plt.figure()\n",
    "plt.plot(outcomes, pmf, \"ks\")\n",
    "plt.xlabel(\"Counts per measurement\")\n",
    "plt.ylabel(\"Probability mass function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ce46b",
   "metadata": {},
   "source": [
    "<font size=3><u>**In-class discussion: What is the uncertainty on the measured counts?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "Since it's Poisson, the standard deviation is the square root of the expected value!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7750e27",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Compute the uncertainty on the measured counts using either a formula, or a `scipy` function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40430b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_uncertainty = ...\n",
    "print(f\"Uncertainty: {counts_uncertainty:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1413ee",
   "metadata": {},
   "source": [
    "## 1.2. Estimating the luminosity of a source\n",
    "\n",
    "\n",
    "<font size=3><u>**In-class discussion: Let's do the opposite now! We found a source that emitted 5 counts. What is the luminosity of the source?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "The Poisson distribution above peaks at 5 counts, but also for 4 counts. So... if we got 4 counts, 5 would also be a good answer?\n",
    "There is something weird going on! We have one measurement and we ask a question about the source! Also, we are always going to get integer multiples of the count/luminosty factor this way! But nature doesn't care about the photons we got, how far away we are, etc.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587b7120",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Select three offsets, including zero, (can be negative or positive value) around the mean value and inspect the resulting distributions: what do you notice?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = np.arange(0, int(expected_counts*3)+1, 1)\n",
    "plt.figure()\n",
    "# try different offsets around the expected mean value and plot the PMF\n",
    "for offset, marker in zip([..., ..., ...], [\"s\", \"o\", \"d\"]):\n",
    "    mean = expected_counts + offset\n",
    "    plt.plot(outcomes, st.poisson(mean).pmf(outcomes), \":\", marker=marker, alpha=0.8, label=f\"Mean = {mean:.4g}\")\n",
    "plt.axvline(expected_counts, color=\"0.5\", alpha=0.5, label=\"k=5\")\n",
    "plt.ylim(ymin=0)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Counts\")\n",
    "plt.ylabel(\"Probability mass function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb415e",
   "metadata": {},
   "source": [
    "### We have multiple (actually infinite) hypotheses for the source luminosity\n",
    "\n",
    "Before, we had the **source luminosity fixed**, and we wondered what we will measure, if repeating the experiment many times! This is the <span style=\"color:#d87c3a\">**frequentist approach**</span>. And we also assigned uncertainty in the data!!!\n",
    "\n",
    "> **A frequentist assigns probabilities to data - parameters are fixed. The probability is a *frequency* of data outcomes.**\n",
    "\n",
    "But when asking about the nature of things (like in... all Science except for mathematics), then we are not interested in assigning uncertainty on the data. The data are what they are - also... they might have been fundamentally unique (some experiments cannot be repeated). We need to *assign probabilities to the quantity of interest*. This is the <span style=\"color:#d87c3a\">**Bayesian approach**</span>:\n",
    "\n",
    "$$ P(\\textrm{hypothesis} | \\textrm{data}) $$\n",
    "\n",
    "> **A Bayesian assigns probabilities to hypotheses. The probability is a *degree of belief* in a value of a parameter.**\n",
    "\n",
    "![image from Sivia](images/Sivia_Logic.png)\n",
    "\n",
    "# 2. Bayes Theorem: The Foundation of Bayesian Inference\n",
    "\n",
    "To navigate from what we can model, $P(\\textrm{data} | \\textrm{hypothesis})$, to what we want to know, $P(\\textrm{hypothesis} | \\textrm{data})$, we use **Bayes Theorem**. It arises from the basic rules of probability.\n",
    "\n",
    "The joint probability of two events (or propositions) A and B occurring, $P(A, B)$, can be written in two ways:\n",
    "\n",
    "$$ P(A, B) = P(A | B) P(B) $$\n",
    "\n",
    "$$ P(A, B) = P(B | A) P(A) $$\n",
    "\n",
    "Since $P(A,B)$ is the same in both expressions, we can equate them:\n",
    "\n",
    "$$ P(A | B) P(B) = P(B | A) P(A) $$\n",
    "\n",
    "Rearranging this gives us Bayes Theorem:\n",
    "\n",
    "$$ P(A | B) = \\dfrac{P(B | A) P(A)}{P(B)} $$\n",
    "\n",
    "In the context of data and hypotheses, we write this as:\n",
    "\n",
    "$$ P(\\textrm{hypothesis} | \\textrm{data}, I) = \\dfrac{P(\\textrm{data} | \\textrm{hypothesis}, I) P(\\textrm{hypothesis} | I)}{P(\\textrm{data} | I)} $$\n",
    "\n",
    "Here, $I$ represents *all our background information and assumptions*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7529ecf",
   "metadata": {},
   "source": [
    "We made everything conditional to $I$, the **background information**: all relevant knowledge we have about the problem we are solving but are not part of the data or the specific hypothesis being tested.\n",
    "\n",
    "For example, if we are testing whether a die is fair, the data are a sequence of outcomes (e.g., 1, 6, 3, 5, 3, 1), the hypothesis could be **the probability of rolling a 6 is $p_6$**, and $I$ = $\\big\\{$ all dice have 6 sides, a fair die has equiprobable sides, the laws of physics as we know them, $\\cdots \\big\\}$.\n",
    "\n",
    "For brevity, **we usually omit writing the $I$** in the equations, but **its always there**... somewhere in the background!\n",
    "\n",
    "All the terms of Bayes Theorem have specific names:\n",
    "\n",
    "*   <span style=\"color:#d87c3a\">**Posterior Probability**</span>: $P(\\text{hypothesis} | \\text{data}, I)$ is the (updated) degree of belief in the hypothesis *after* considering the data.\n",
    "*   <span style=\"color:#d87c3a\">**Likelihood**</span>: $P(\\text{data | hypothesis}, I)$ is the probability of observing the data *given* that the hypothesis is true. This is what we often model based on our understanding of the data generation process.\n",
    "*   <span style=\"color:#d87c3a\">**Prior Probability**</span>: $P(\\text{hypothesis} | I)$ is the degree of belief in the hypothesis *before* looking at the current data. It encapsulates our previous knowledge, physical constraints, or initial assumptions.\n",
    "*   <span style=\"color:#d87c3a\">**Evidence (or Marginal Likelihood)**</span>: $P(\\text{data} | I)$ is the overall probability of observing the data, averaged over all possible hypotheses.\n",
    "\n",
    "> In Bayesian Analysis we assign degrees of belief to hypotheses (prior), which we \"update\" using experimental data (via the likelihood), to arrive at a new, refined degree of belief in the hypotheses (posterior)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7113c318",
   "metadata": {},
   "source": [
    "# 3. A Deeper Look at the Components:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2367d",
   "metadata": {},
   "source": [
    "## 3.1. Priors $P(\\text{hypothesis} | I)$\n",
    "The <span style=\"color:#d87c3a\">prior</span> represents our state of knowledge about the hypothesis *before we consider the current dataset*. It can come from previous experiments, theoretical predictions, or fundamental principles. The choice of prior can be influential, especially with limited data, and is a key aspect of Bayesian modeling.\n",
    "\n",
    "Priors can be broadly categorized as **informative** or **uninformative** (often, more accurately, **weakly informative**).\n",
    "\n",
    "*   <span style=\"color:#d87c3a\">**Informative Priors**</span>: These reflect specific, <span style=\"color:#d87c3a\">existing information</span> about the parameter before observing the current data. This information might come from previous experiments, physical laws, or established theories. For example, if measuring the mass of a planet, an informative prior might restrict the mass to be positive and perhaps within a range plausible for planets.\n",
    "\n",
    "*   <span style=\"color:#d87c3a\">**Uninformative/Weakly Informative Priors**</span>: These are intended to <span style=\"color:#d87c3a\">let the data speak for themselves</span> as much as possible, or to represent a state of relative ignorance. However, a truly \"uninformative\" prior is often elusive. The most common approach is to use **uniform priors**. Those assign equal probability to all possible values of a parameter within a given range. For a parameter $\\theta$ bounded by $\\theta_{min}$ and $\\theta_{max}$, $P(\\theta|I) \\propto 1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "# Uniform Prior\n",
    "x_uniform = np.linspace(-2, 12, 500)\n",
    "pdf_uniform = st.uniform(loc=0, scale=10).pdf(x_uniform) # Uniform between 0 and 10\n",
    "plt.plot(x_uniform, pdf_uniform, label='Uniform Prior P(θ|I) ~ U(0, 10)')\n",
    "plt.title('Uniform Prior')\n",
    "plt.xlabel('Parameter value θ')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801da0e7",
   "metadata": {},
   "source": [
    "> The choice of prior should always be justified and its impact on the results assessed, especially if strong claims are made from weakly informative data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8621672",
   "metadata": {},
   "source": [
    "## 3.2. Likelihood $P(\\text{data} | \\text{hypothesis}, I)$\n",
    "The <span style=\"color:#d87c3a\">likelihood function</span>, $P(\\text{data} | \\text{hypothesis}, I)$, is the cornerstone that <span style=\"color:#d87c3a\">connects our observed data to the parameters of our hypothesis</span>. If the data are very probable under the hypothesis, the likelihood is high. If the data are improbable, the likelihood is low. For many problems, we assume a specific mathematical form for the likelihood. Choosing an appropriate likelihood is crucial as it <span style=\"color:#d87c3a\">encapsulates our assumptions about the data-generating process</span>. The form of the likelihood is <span style=\"color:#d87c3a\">determined by the nature of the data and the underlying physical or statistical model</span> we believe is responsible for producing that data.\n",
    "\n",
    "### How to Choose a Likelihood:\n",
    "\n",
    "The choice primarily depends on:\n",
    "1.  **Type of Data**: Is the data continuous (e.g., measurements of temperature, flux), discrete counts (e.g., number of photons, detected events), binary (e.g., success/failure), or categorical?\n",
    "2.  **Assumed Data-Generating Process**: What statistical distribution best describes the variability or noise in the data, given a set of model parameters?\n",
    "\n",
    "**Most Common Likelihood Functions and Their Use Cases:**\n",
    "\n",
    "The two most commonly used likelihood functions are:\n",
    "\n",
    "*   **Gaussian (Normal) Likelihood**:\n",
    "    *   **Use Case**: For <span style=\"color:#d87c3a\">continuous data</span> that are expected to be <span style=\"color:#d87c3a\">symmetrically distributed</span> around a mean value, or when the <span style=\"color:#d87c3a\">errors are assumed to be normally distributed</span> (often invoked by the Central Limit Theorem).\n",
    "    *   **Example**: Measuring the brightness of a star, where instrumental noise and other random errors lead to Gaussian fluctuations around the true brightness.\n",
    "    *   **Form**: If we have $N$ data points $x_i$, and our hypothesis is that they are drawn from a Gaussian with mean $\\mu$ and standard deviation $\\sigma$ (where $\\mu$ and/or $\\sigma$ could be our parameters):\n",
    "        $$ P(\\{x_i\\} | \\mu, \\sigma, I) = \\prod_{i=1}^N \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right) $$\n",
    "\n",
    "*   **Poisson Likelihood**:\n",
    "    *   **Use Case**: For <span style=\"color:#d87c3a\">count data</span>, representing the number of events occurring in a fixed interval of time or space, assuming events are <span style=\"color:#d87c3a\">independent</span> and occur at a <span style=\"color:#d87c3a\">constant average rate</span>.\n",
    "    *   **Example**: Counting the number of X-ray photons ($k$) detected from a celestial source in a given observation time, where the expected mean count is $\\lambda$. This is the primary example in this notebook.\n",
    "    *   **Form**: If we observe $k$ counts and the expected mean is $\\lambda$:\n",
    "        $$ P(k | \\lambda, I) = \\frac{\\lambda^k e^{-\\lambda}}{k!} $$\n",
    "\n",
    "\n",
    "**Constructing a Likelihood:**\n",
    "\n",
    "*   **Based on Physical Models**: Often, the likelihood is derived from a physical model of the measurement process. For instance, if your instrument has a known response function, this function will inform the likelihood.\n",
    "*   **Combining Distributions**: More complex likelihoods can be built by combining simpler ones, e.g., a mixture model if data can arise from different processes, or a convolution if there are multiple sources of error.\n",
    "*   **Numerical Likelihoods**: If an analytical form is intractable, the likelihood might be evaluated numerically based on simulations of the data-generating process for different parameter values.\n",
    "\n",
    "**Important Considerations:**\n",
    "\n",
    "*   The likelihood is a function of the **parameters** of your hypothesis, for the **fixed, observed data**.\n",
    "*   The choice of likelihood is a modeling choice and should be justified. If the assumptions underlying the chosen likelihood are strongly violated by the data-generating process, the Bayesian inference results may be misleading.\n",
    "*   Sometimes, robust likelihoods (e.g., Student's t-distribution instead of Gaussian for data with heavy tails) are used to make inferences less sensitive to outliers.\n",
    "\n",
    "Understanding and correctly specifying the likelihood is arguably the most critical step in a Bayesian (and frequentist) analysis, as it defines how the data inform our beliefs about the hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74032697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Plots of Common Likelihood Functions\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs = axs.ravel() # Flatten the 1x2 array of axes for easy iteration\n",
    "\n",
    "# 1. Gaussian Likelihood\n",
    "mu_g, sigma_g = 0, 1.0 # Example parameters: mean, std_dev\n",
    "x_g = np.linspace(mu_g - 4*sigma_g, mu_g + 4*sigma_g, 200)\n",
    "pdf_g = st.norm.pdf(x_g, loc=mu_g, scale=sigma_g)\n",
    "axs[0].plot(x_g, pdf_g, label=f'Gaussian(μ={mu_g}, σ={sigma_g})')\n",
    "axs[0].set_title('Gaussian Likelihood')\n",
    "axs[0].set_xlabel('Data Value (x)')\n",
    "axs[0].set_ylabel('Probability Density P(x|μ,σ)')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True, alpha=0.5)\n",
    "\n",
    "# 2. Poisson Likelihood\n",
    "lambda_p = 5 # Example parameter: expected rate λ\n",
    "k_p = np.arange(0, lambda_p * 3 + 1)\n",
    "pmf_p = st.poisson.pmf(k_p, mu=lambda_p)\n",
    "axs[1].plot(k_p, pmf_p, 'o-', label=f'Poisson(λ={lambda_p})')\n",
    "axs[1].set_title('Poisson Likelihood')\n",
    "axs[1].set_xlabel('Number of Events (k)')\n",
    "axs[1].set_ylabel('Probability Mass P(k|λ)')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True, alpha=0.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80662650",
   "metadata": {},
   "source": [
    "## 3.3. The Evidence $P(\\text{data} | I)$:\n",
    "The evidence is the probability of the data, averaged over all possible values of the hypothesis parameters, weighted by their prior probabilities. If $\\theta$ represents the parameters of our hypothesis, then:\n",
    "$$ P(\\text{data} | I) = \\int P(\\text{data} | \\theta, I) P(\\theta | I) d\\theta $$\n",
    "In parameter estimation problems (where we are trying to find the best values of $\\theta$), the evidence $P(\\text{data} | I)$ is a constant for a given dataset and model form. It ensures that the posterior probability distribution is properly normalized (i.e., integrates/sums to 1). While it often cancels out or is <span style=\"color:#d87c3a\">ignored in parameter estimation</span> (as we often care about $P(\\text{hypothesis} | \\text{data}) \\propto P(\\text{data} | \\text{hypothesis}) P(\\text{hypothesis})$), the evidence is <span style=\"color:#d87c3a\">**crucial for model comparison**</span>, a topic we will explore later. It allows us to compare how well different models (different forms of hypotheses or priors) explain the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da08bfa",
   "metadata": {},
   "source": [
    "# 4. Back to our counting experiment: what does Bayes say about it...\n",
    "\n",
    "$$ P(\\text{hypothesis} | \\text{data}) = P(\\lambda | k) \\propto P(k | \\lambda) P(\\lambda) $$\n",
    "\n",
    "where we ignored the evidence since its just a normalization constant for parameter estimation.\n",
    "\n",
    "## 4.1. Assigning a prior belief on the source luminosity (and therefore its expected counts, $\\lambda$)\n",
    "\n",
    "We need to choose a prior $P(\\lambda | I)$.\n",
    "\n",
    "**Option 1: Uniform Prior over a finite range (Principle of Indifference)**\n",
    "We may have a constraint - that $\\lambda$ cannot be above 20 because that would make it an AGN, and we know from other measurements that its not (this is background information $I$):\n",
    "\n",
    "$$ P(\\lambda | I) = \\begin{cases} C & 0\\leq \\lambda < 20 \\\\ 0 & \\text{elsewhere} \\end{cases}$$\n",
    "\n",
    "The constant $C$ would be $1/20$ to normalize the prior. However, since we are interested in the shape of the posterior $P(\\lambda | k) \\propto P(k | \\lambda) P(\\lambda)$, we can often absorb normalization constants.\n",
    "\n",
    "Then using the Poisson likelihood as in the frequentist approach:\n",
    "\n",
    "$$ P(\\lambda | k) \\propto P(k | \\lambda) P(\\lambda) \\propto \\begin{cases} \\dfrac{\\lambda^k e^{-\\lambda}}{k!}  & 0\\leq \\lambda < 20 \\\\ 0 & \\text{elsewhere} \\end{cases}$$\n",
    "\n",
    "**Option 2: Uniform (Improper) Prior for $\\lambda \\ge 0$ (Agnostic approach)**\n",
    "Maybe we have no other information and want to be **agnostic** about $\\lambda$ (other than it must be non-negative, as its an expected count):\n",
    "\n",
    "$$  P(\\lambda | I) = \\text{const.}, \\quad \\lambda \\ge 0 $$\n",
    "\n",
    "This is an **improper prior** because its integral over $[0, \\infty)$ diverges. However, it can still lead to a proper posterior. Since its just a constant, it does not affect the proportionality for the posterior shape:\n",
    "\n",
    "$$ P(\\lambda | k) \\propto P(k | \\lambda) P(\\lambda) \\propto P(k | \\lambda) \\propto \\dfrac{\\lambda^k e^{-\\lambda}}{k!} \\quad \\text{for } \\lambda \\ge 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb232f",
   "metadata": {},
   "source": [
    "\n",
    "<font size=3><u>**In-class discussion: Are we back to frequentism using uniform priors?**</u><font>\n",
    "\n",
    "_Discuss with your teammate, then report._\n",
    "\n",
    "<details>\n",
    "<summary><b>[Spoiler]</b></summary>\n",
    "<br>\n",
    "No! Bayesian inference is not just frequentism + priors. Even if the formula for the posterior $P(\\lambda|k)$ looks proportional to the likelihood $P(k|\\lambda)$ when using a flat prior, the interpretation is fundamentally different. \n",
    "<br><br>\n",
    "The posterior $P(\\lambda|k)$ is a probability distribution for the parameter $\\lambda$, given the observed data $k$. The likelihood $P(k|\\lambda)$ is a probability distribution for the data $k$, given a fixed parameter $\\lambda$.\n",
    "<br><br>\n",
    "The posterior $P(\\lambda | k) \\propto \\lambda^k e^{-\\lambda}$ (for $k$ fixed, $\\lambda \\ge 0$) is a probability density function for the continuous quantity $\\lambda$. In fact, it is a Gamma distribution: specifically, $\\text{Gamma}(\\text{shape}=k+1, \\text{scale}=1)$ or $\\text{Gamma}(\\alpha=k+1, \\beta=1)$ depending on parameterization (e.g., if PDF is $f(x;\\alpha,\\beta) = \\frac{\\beta^\\alpha x^{\\alpha-1}e^{-\\beta x}}{\\Gamma(\\alpha)}$).\n",
    "<br><br>\n",
    "So MLE is rooted in the frequentist idea of how often data like ours would be observed if a parameter had a certain value. Bayesian inference provides a probabilistic statement about the parameter itself, given the observed data and prior beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329cecb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Compute the posterior values for the trial $\\lambda$ values. What is the best-fitting value for $\\lambda$?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_counts = 5.0\n",
    "lambda_values = np.linspace(0, int(measure_counts*3)+1, 100)\n",
    "posteriors = ...\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lambda_values, posteriors, \"k-\")\n",
    "plt.xlabel(\"Expected counts ($\\lambda$)\")\n",
    "plt.ylabel(\"Posterior probability density\")\n",
    "plt.axvline(5.0, color=\"r\", ls=\":\", label=\"Measured counts\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468f3559",
   "metadata": {},
   "source": [
    "# 5. Parameter Marginalization: Focusing on What Matters\n",
    "\n",
    "Often, our statistical models involve multiple parameters. However, we might only be interested in a subset of these parameters, while the others are necessary for a complete model but not of direct interest. These latter parameters are often called **nuisance parameters**.\n",
    "\n",
    "For example, when measuring the flux ($\\mu$) of a star, the noise level or background uncertainty ($\\sigma$) in our measurements might also be an unknown parameter that we need to account for in our model. While we need to estimate $\\sigma$ to properly assess $\\mu$, our primary goal is the value of $\\mu$, making $\\sigma$ a nuisance parameter in this context.\n",
    "\n",
    "Bayesian inference provides a natural and powerful way to deal with nuisance parameters through **marginalization**. If we have a joint posterior probability distribution for all parameters, say $P(\\theta_1, \\theta_2, ..., \\theta_k | \\text{data}, I)$, and we are only interested in a specific parameter (or subset of parameters) $\\theta_1$, we can obtain its marginal posterior probability distribution by integrating (or summing, for discrete parameters) the joint posterior over all other nuisance parameters ($\\theta_2, ..., \\theta_k$):\n",
    "\n",
    "$$ P(\\theta_1 | \\text{data}, I) = \\int \\dots \\int P(\\theta_1, \\theta_2, \\dots, \\theta_k | \\text{data}, I) d\\theta_2 \\dots d\\theta_k $$\n",
    "\n",
    "For a two-parameter case (e.g., $\\mu$ and $\\sigma$):\n",
    "$$ P(\\mu | \\text{data}, I) = \\int P(\\mu, \\sigma | \\text{data}, I) d\\sigma $$\n",
    "\n",
    "The result, $P(\\theta_1 | \\text{data}, I)$, is the posterior probability distribution for $\\theta_1$ alone, fully accounting for the uncertainty in the nuisance parameters. This means that our inferences about $\\theta_1$ (like its credible interval) have properly incorporated the fact that the other parameters were not known precisely.\n",
    "\n",
    "This is a significant advantage of the Bayesian framework. It allows us to propagate uncertainty from all parts of our model into the final inference for the quantities we care about. In frequentist statistics, dealing with nuisance parameters can sometimes be more complex, often involving techniques like profiling the likelihood or using specific test statistics designed to be insensitive to them.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/marginalization_conditioning_example.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65ffd7",
   "metadata": {},
   "source": [
    "#### Example: Estimating Stellar Flux with Background as a Nuisance Parameter\n",
    "\n",
    "Let’s apply marginalization in a practical setting.\n",
    "\n",
    "Suppose we observe a noisy measurement of the total brightness from a patch of sky. This total brightness includes contributions from:\n",
    "\n",
    "* The **flux** $F$ of a star (our parameter of interest),\n",
    "* The **background** $B$ from surrounding light or instrumental effects (a nuisance parameter),\n",
    "* And **Gaussian noise** with known standard deviation $\\sigma$.\n",
    "\n",
    "We model the observed value $x$ as:\n",
    "\n",
    "$$\n",
    "x \\sim \\mathcal{N}(F + B, \\sigma^2)\n",
    "$$\n",
    "\n",
    "We will place a **broad prior** on $F$, reflecting that the star could be relatively bright or dim, and a **more informative prior** on $B$, reflecting prior knowledge about typical background levels:\n",
    "\n",
    "$$\n",
    "P(F \\mid I) \\sim \\mathcal{N}(F; \\mu_F=10.0, \\sigma_F=5.0), \\quad P(B \\mid I) \\sim \\mathcal{N}(B; \\mu_B=2.0, \\sigma_B=1.0)\n",
    "$$\n",
    "\n",
    "Although both $F$ and $B$ are unknown, we are only interested in the posterior for $F$. To obtain it, we **marginalize out** the nuisance parameter $B$:\n",
    "\n",
    "$$\n",
    "P(F \\mid x) = \\int P(F, B \\mid x) \\, dB\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2cfaad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"margin-top: 20px\">\n",
    "\n",
    "**Task:**  Define the priors, likelihood, joint posterior, and marginal posterior for $F$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.integrate import quad\n",
    "\n",
    "\n",
    "# Simulated data\n",
    "true_flux = 10.0\n",
    "true_background = 2.0\n",
    "sigma = 1.0\n",
    "\n",
    "# One observation (flux + background + noise)\n",
    "np.random.seed(42)\n",
    "obs = np.random.normal(loc=true_flux + true_background, scale=sigma)\n",
    "\n",
    "print(f\"Observed value: {obs:.2f}\")\n",
    "\n",
    "# Define priors\n",
    "def prior_flux(F):\n",
    "    return ...\n",
    "\n",
    "def prior_background(B):\n",
    "    return ...\n",
    "\n",
    "# Likelihood\n",
    "def likelihood(obs, F, B):\n",
    "    return ...\n",
    "\n",
    "# Posterior (unnormalized, joint in F and B)\n",
    "def joint_posterior(F, B):\n",
    "    return ...\n",
    "\n",
    "# Marginal posterior over F (integrate out B)\n",
    "def marginal_posterior_F(F):\n",
    "    integrand = lambda B: joint_posterior(F, B)\n",
    "    result, _ = quad(..., ..., ...)\n",
    "    return result\n",
    "\n",
    "# Evaluate marginal posterior over a grid\n",
    "F_vals = np.linspace(5, 15, 200)\n",
    "posterior_vals = np.array([marginal_posterior_F(F) for F in F_vals])\n",
    "\n",
    "# Normalize\n",
    "posterior_vals /= np.trapz(posterior_vals, F_vals)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(F_vals, posterior_vals, label='Marginal posterior of flux')\n",
    "plt.axvline(true_flux, color='k', linestyle='--', label='True flux')\n",
    "plt.xlabel('Flux')\n",
    "plt.ylabel('Posterior density')\n",
    "plt.legend()\n",
    "plt.title('Marginalization over nuisance parameter (background)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
